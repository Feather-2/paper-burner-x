// api-config-builder.js
// APIé…ç½®æž„å»ºæ¨¡å—

(function() {
  'use strict';

  // =====================
  // buildCustomApiConfig: å…¼å®¹è‡ªå®šä¹‰æ¨¡åž‹è°ƒç”¨
  // =====================
  /**
   * æž„å»ºè‡ªå®šä¹‰ API è®¿é—®é…ç½®ã€‚
   * è¯¥å‡½æ•°è´Ÿè´£æ ¹æ®ä¼ å…¥çš„å‚æ•°ï¼Œç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„ API è¯·æ±‚é…ç½®å¯¹è±¡ï¼Œ
   * åŒ…æ‹¬è¯·æ±‚ç«¯ç‚¹ã€æ¨¡åž‹IDã€è¯·æ±‚å¤´ã€è¯·æ±‚ä½“æž„å»ºå™¨ã€å“åº”æå–å™¨ä»¥åŠæµå¼æ”¯æŒç­‰ã€‚
   *
   * ä¸»è¦é€»è¾‘ï¼š
   * 1. ç«¯ç‚¹å¤„ç†ï¼šå¦‚æžœ `window.modelDetector` å­˜åœ¨ä¸”èƒ½æä¾›å®Œæ•´ç«¯ç‚¹ï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨ã€‚
   *    å¦åˆ™ï¼Œå¦‚æžœæä¾›çš„ `customApiEndpoint` ä¸è§„èŒƒï¼ˆä¸å« `/v1/` æˆ– `/v1` ç»“å°¾ï¼‰ï¼Œ
   *    ä¼šè‡ªåŠ¨æ‹¼æŽ¥ `/v1/chat/completions`ã€‚
   * 2. è¯·æ±‚æ ¼å¼è‡ªåŠ¨æŽ¨æ–­ï¼šå¦‚æžœ `customRequestFormat` ä¸ºç©ºä¸”ç«¯ç‚¹ä»¥ `/v1/chat/completions` ç»“å°¾ï¼Œ
   *    åˆ™è‡ªåŠ¨è®¾ç½®ä¸º `openai` æ ¼å¼ã€‚
   * 3. æ¨¡åž‹IDèŽ·å–ï¼šå¦‚æžœ `window.modelDetector` å­˜åœ¨ï¼Œåˆ™å°è¯•èŽ·å–å½“å‰é€‰æ‹©çš„æ¨¡åž‹IDã€‚
   * 4. æ ¹æ® `customRequestFormat` (å¦‚ 'openai', 'anthropic', 'gemini' ç­‰) æž„å»ºç‰¹å®šé…ç½®ï¼š
   *    - è®¾ç½®è®¤è¯å¤´ (Authorization, x-api-key)ã€‚
   *    - å®šä¹‰ `bodyBuilder` ç”¨äºŽæž„å»ºéžæµå¼è¯·æ±‚çš„è¯·æ±‚ä½“ã€‚
   *    - å®šä¹‰ `streamBodyBuilder` ç”¨äºŽæž„å»ºæµå¼è¯·æ±‚çš„è¯·æ±‚ä½“ã€‚
   *    - å®šä¹‰ `responseExtractor` ç”¨äºŽä»Ž API å“åº”ä¸­æå–æ‰€éœ€å†…å®¹ã€‚
   *    - è®¾ç½® `streamSupport` æ ‡è®°æ˜¯å¦æ”¯æŒæµå¼å“åº”ã€‚
   *    - ä¸º Gemini ç­‰ç‰¹æ®Šæ¨¡åž‹å¤„ç†ç«¯ç‚¹å‚æ•° (å¦‚ `alt=sse`)ã€‚
   * 5. å¯¹äºŽä¸æ”¯æŒçš„ `customRequestFormat`ï¼Œä¼šæŠ›å‡ºé”™è¯¯ã€‚
   * 6. æœ€ç»ˆè¿”å›žæž„å»ºå¥½çš„ `config` å¯¹è±¡ã€‚
   *
   * @param {string} key API å¯†é’¥ã€‚
   * @param {string} customApiEndpoint è‡ªå®šä¹‰ API ç«¯ç‚¹åŸºç¡€ URLã€‚
   * @param {string} customModelId è‡ªå®šä¹‰æ¨¡åž‹ IDã€‚
   * @param {string} customRequestFormat è‡ªå®šä¹‰è¯·æ±‚æ ¼å¼ (ä¾‹å¦‚ 'openai', 'anthropic', 'gemini')ã€‚
   * @param {number} [temperature] æ¨¡åž‹æ¸©åº¦å‚æ•°ï¼ŒæŽ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ã€‚
   * @param {number} [max_tokens] æ¨¡åž‹æœ€å¤§è¾“å‡º token æ•°ã€‚
   * @returns {object} æž„å»ºå¥½çš„ API é…ç½®å¯¹è±¡ï¼ŒåŒ…å« endpoint, modelName, headers, bodyBuilder, responseExtractor, streamSupport, streamBodyBuilder ç­‰ã€‚
   * @throws {Error} å¦‚æžœ customRequestFormat ä¸è¢«æ”¯æŒã€‚
   */

  // è¾…åŠ©å‡½æ•°ï¼šå¦‚æžœ userContent æ˜¯æ•°ç»„ï¼Œåˆ™æå–å…¶ä¸­çš„æ–‡æœ¬å†…å®¹
  const extractTextFromUserContent = (userContent) => {
    if (Array.isArray(userContent)) {
      const textPart = userContent.find(part => part.type === 'text');
      return textPart ? textPart.text : '';
    }
    return userContent; // å‡è®¾å·²ç»æ˜¯å­—ç¬¦ä¸²
  };

  // è¾…åŠ©å‡½æ•°ï¼šå°† OpenAI é£Žæ ¼çš„ userContent è½¬æ¢ä¸º Gemini æ ¼å¼
  const convertOpenAIToGeminiParts = (userContent) => {
    if (Array.isArray(userContent)) {
      return userContent.map(part => {
        if (part.type === 'text') {
          return { text: part.text };
        } else if (part.type === 'image_url' && part.image_url && part.image_url.url) {
          const base64Data = part.image_url.url.split(',')[1];
          if (!base64Data) return null;
          const mimeType = part.image_url.url.match(/^data:(image\/\w+);base64,/)?.[1] || 'image/jpeg';
          return { inlineData: { mimeType: mimeType, data: base64Data } };
        }
        return null;
      }).filter(p => p);
    }
    return [{ text: userContent }]; // å‡è®¾ä¸ºå­—ç¬¦ä¸²
  };

  // è¾…åŠ©å‡½æ•°ï¼šå°† OpenAI é£Žæ ¼çš„ userContent è½¬æ¢ä¸º Anthropic æ ¼å¼
  const convertOpenAIToAnthropicContent = (userContent) => {
    if (Array.isArray(userContent)) {
      return userContent.map(part => {
        if (part.type === 'text') {
          return { type: 'text', text: part.text };
        } else if (part.type === 'image_url' && part.image_url && part.image_url.url) {
          const base64Data = part.image_url.url.split(',')[1];
          if (!base64Data) return null;
          const mediaType = part.image_url.url.match(/^data:(image\/\w+);base64,/)?.[1] || 'image/jpeg';
          return { type: 'image', source: { type: 'base64', media_type: mediaType, data: base64Data } };
        }
        return null;
      }).filter(p => p);
    }
    return [{ type: 'text', text: userContent }]; // å‡è®¾ä¸ºå­—ç¬¦ä¸²
  };

  const appendPathSegment = (base, segment) => {
    if (!base) return segment || '';
    if (!segment) return base;
    const hasTrailingSlash = base.endsWith('/');
    const hasLeadingSlash = segment.startsWith('/');
    if (hasTrailingSlash && hasLeadingSlash) {
      return base + segment.slice(1);
    }
    if (!hasTrailingSlash && !hasLeadingSlash) {
      return `${base}/${segment}`;
    }
    return base + segment;
  };

  const normalizeOpenAIEndpointForChatbot = (baseApiUrlInput, format, endpointMode = 'auto', targetSegment) => {
    if (!baseApiUrlInput || typeof baseApiUrlInput !== 'string') {
      throw new Error('è‡ªå®šä¹‰æ¨¡åž‹éœ€è¦æä¾› API Base URL');
    }

    const trimmed = baseApiUrlInput.trim();
    if (!trimmed) {
      throw new Error('è‡ªå®šä¹‰æ¨¡åž‹éœ€è¦æä¾› API Base URL');
    }

    const mode = endpointMode || 'auto';
    const normalizedSegment = (targetSegment
      ? targetSegment
      : ((format || '').toLowerCase() === 'anthropic' ? 'messages' : 'chat/completions'))
      .replace(/^\/+/, '');

    const lower = trimmed.toLowerCase();
    const base = trimmed.replace(/\/+$/, '');
    const v1Segment = normalizedSegment.startsWith('v1/') ? normalizedSegment : `v1/${normalizedSegment}`;

    const terminalPaths = [
      normalizedSegment,
      `/${normalizedSegment}`,
      v1Segment,
      `/${v1Segment}`
    ];

    if (terminalPaths.some(path => lower.endsWith(path))) {
      return base;
    }

    if (mode === 'manual') {
      return base;
    }

    if (mode === 'chat') {
      return appendPathSegment(base, normalizedSegment);
    }

    if (/\/v1$/.test(lower)) {
      return appendPathSegment(base, normalizedSegment);
    }

    return appendPathSegment(base, v1Segment);
  };

  function buildCustomApiConfig(key, customApiEndpoint, customModelId, customRequestFormat, temperature, max_tokens, options = {}) {
    let apiEndpoint = customApiEndpoint;
    let modelId = customModelId;
    const endpointMode = options.endpointMode || 'auto';
    let resolvedRequestFormat = customRequestFormat;

    // èŽ·å–å½“å‰é€‰æ‹©çš„æ¨¡åž‹IDï¼ˆå¦‚æžœæœ‰æ¨¡åž‹æ£€æµ‹æ¨¡å—ï¼‰
    if (typeof window.modelDetector !== 'undefined') {
      const currentModelId = window.modelDetector.getCurrentModelId();
      if (currentModelId) {
        modelId = currentModelId;
      }
    }

    // æ–°å¢žï¼šå¦‚æžœ customRequestFormat ä¸ºç©ºä¸” endpoint ä»¥ /v1/chat/completions ç»“å°¾ï¼Œåˆ™è‡ªåŠ¨è®¾ä¸º openai
    if ((!resolvedRequestFormat || resolvedRequestFormat === '') && apiEndpoint && apiEndpoint.endsWith('/v1/chat/completions')) {
      resolvedRequestFormat = 'openai';
    }

    // æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡åž‹æ£€æµ‹æ¨¡å—ï¼Œå¦‚æžœæœ‰åˆ™ä½¿ç”¨å…¶æä¾›çš„å®Œæ•´ç«¯ç‚¹
    // æ³¨æ„ï¼šçŽ°åœ¨ resolvedRequestFormat å·²ç»ç¡®å®šï¼Œç«¯ç‚¹æ ‡å‡†åŒ–ä¼šä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
    if (typeof window.modelDetector !== 'undefined' && typeof window.modelDetector.getFullApiEndpoint === 'function') {
      const fullEndpoint = window.modelDetector.getFullApiEndpoint();
      if (fullEndpoint) {
        apiEndpoint = fullEndpoint;
      } else {
        apiEndpoint = normalizeOpenAIEndpointForChatbot(apiEndpoint, resolvedRequestFormat, endpointMode);
      }
    } else {
      apiEndpoint = normalizeOpenAIEndpointForChatbot(apiEndpoint, resolvedRequestFormat, endpointMode);
    }

    const config = {
      endpoint: apiEndpoint,
      modelName: modelId, // ä½¿ç”¨æœ€æ–°èŽ·å–çš„modelId
      headers: { 'Content-Type': 'application/json' },
      bodyBuilder: null,
      responseExtractor: null,
      streamSupport: false, // é»˜è®¤ä¸æ”¯æŒæµå¼
      streamBodyBuilder: null // æµå¼è¯·æ±‚æž„å»ºå™¨
    };

    const normalizedFormat = (resolvedRequestFormat || 'openai').toLowerCase();

    switch (normalizedFormat) {
      case 'openai':
      case 'openai-vision': // Add a specific format for vision-enabled OpenAI
        config.headers['Authorization'] = `Bearer ${key}`;
        config.bodyBuilder = (sys_prompt, user_content) => ({ // user_content can be string or array
          model: modelId,
          messages: [{ role: "system", content: sys_prompt }, { role: "user", content: user_content }],
          temperature: temperature ?? 0.5,
          max_tokens: max_tokens ?? 8000
        });

        // æµå¼è¯·æ±‚æž„å»ºå™¨ - é’ˆå¯¹è½¬æŽ¥ç«™å…¼å®¹æ€§ä¼˜åŒ–
        config.streamBodyBuilder = (sys, msgs, user_content) => {
          // æ£€æµ‹æ˜¯å¦æ˜¯ Claude æ¨¡åž‹ + OpenAI æ ¼å¼ï¼ˆè½¬æŽ¥ç«™åœºæ™¯ï¼‰
          const isClaudeViaProxy = modelId && typeof modelId === 'string' && modelId.toLowerCase().includes('claude');

          if (isClaudeViaProxy) {
            // å¯¹äºŽé€šè¿‡è½¬æŽ¥ç«™ä½¿ç”¨çš„ Claude æ¨¡åž‹ï¼Œå°† system prompt åˆå¹¶åˆ°ç¬¬ä¸€æ¡ user æ¶ˆæ¯ä¸­
            // å› ä¸ºå¾ˆå¤šè½¬æŽ¥ç«™ä¸æ­£ç¡®å¤„ç† system role
            console.log('[ApiConfigBuilder] ðŸ”§ æ£€æµ‹åˆ°é€šè¿‡è½¬æŽ¥ç«™ä½¿ç”¨ Claudeï¼Œå°† system prompt åˆå¹¶åˆ° user æ¶ˆæ¯');

            // æž„å»ºåˆå¹¶åŽçš„ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
            let firstUserMessage = sys ? `${sys}\n\n---\n\n` : '';
            if (typeof user_content === 'string') {
              firstUserMessage += user_content;
            } else if (Array.isArray(user_content)) {
              // å¦‚æžœæ˜¯å¤šæ¨¡æ€å†…å®¹ï¼Œåªæå–æ–‡æœ¬éƒ¨åˆ†åˆå¹¶
              const textPart = user_content.find(p => p.type === 'text');
              if (textPart) {
                firstUserMessage += textPart.text;
              }
            }

            return {
              model: modelId,
              messages: [
                ...msgs,
                { role: 'user', content: firstUserMessage }
              ],
              temperature: temperature ?? 0.5,
              max_tokens: max_tokens ?? 8000,
              stream: true
            };
          } else {
            // å…¶ä»–æ¨¡åž‹ä½¿ç”¨æ ‡å‡†æ ¼å¼
            return {
              model: modelId,
              messages: [
                { role: 'system', content: sys },
                ...msgs,
                { role: 'user', content: user_content }
              ],
              temperature: temperature ?? 0.5,
              max_tokens: max_tokens ?? 8000,
              stream: true
            };
          }
        };
        config.responseExtractor = (data) => data?.choices?.[0]?.message?.content;
        config.streamSupport = true;
        break;
      case 'anthropic':
        config.headers['x-api-key'] = key;
        config.headers['anthropic-version'] = '2023-06-01';
        config.bodyBuilder = (sys_prompt, user_content) => ({
          model: modelId,
          system: sys_prompt,
          messages: [{ role: "user", content: convertOpenAIToAnthropicContent(user_content) }],
          temperature: temperature ?? 0.5,
          max_tokens: max_tokens ?? 8000
        });
        config.streamBodyBuilder = (sys, msgs, user_content) => {
          return {
            model: modelId,
            system: sys,
            messages: msgs.length ?
              [...msgs, { role: 'user', content: convertOpenAIToAnthropicContent(user_content) }] :
              [{ role: 'user', content: convertOpenAIToAnthropicContent(user_content) }],
            max_tokens: max_tokens ?? 8000,
            temperature: temperature ?? 0.5,
            stream: true
          };
        };
        config.responseExtractor = (data) => data?.content?.[0]?.text;
        config.streamSupport = true;
        config.streamHandler = 'claude';
        break;
      case 'gemini':
      case 'gemini-preview': // Assuming gemini-preview also supports this
        let baseUrl = config.endpoint.split('?')[0];
        config.endpoint = `${baseUrl}?key=${key}`;
        config.streamEndpoint = `${baseUrl}?key=${key}&alt=sse`;
        const geminiModelIdToUse = modelId || (normalizedFormat === 'gemini-preview' ? 'gemini-1.5-flash-latest' : 'gemini-pro'); // Updated default for preview
        config.modelName = geminiModelIdToUse;

        config.bodyBuilder = (sys_prompt, user_content) => ({
          contents: [{ role: "user", parts: convertOpenAIToGeminiParts(user_content) }],
          generationConfig: { temperature: temperature ?? 0.5, maxOutputTokens: max_tokens ?? 8192 },
          ...(sys_prompt && { systemInstruction: { parts: [{ text: sys_prompt }] }})
        });
        config.streamBodyBuilder = (sys, msgs, user_content) => {
          const geminiMessages = [];
          if (msgs.length) {
            for (const msg of msgs) {
              geminiMessages.push({ role: msg.role === 'assistant' ? 'model' : 'user', parts: convertOpenAIToGeminiParts(msg.content) });
            }
          }
          geminiMessages.push({ role: 'user', parts: convertOpenAIToGeminiParts(user_content) });
          return {
            contents: geminiMessages,
            generationConfig: {
              temperature: temperature ?? 0.5,
              maxOutputTokens: max_tokens ?? 8192,
              ...(normalizedFormat === 'gemini-preview' && { responseModalities: ["TEXT"], responseMimeType: "text/plain" })
            },
            ...(sys && { systemInstruction: { parts: [{ text: sys }] }})
          };
        };
        config.responseExtractor = (data) => {
          if (data?.candidates && data.candidates.length > 0 && data.candidates[0].content) {
            const parts = data.candidates[0].content.parts;
            return parts && parts.length > 0 ? parts.map(p => p.text).join('') : ''; // Join text parts
          }
          return '';
        };
        config.streamSupport = true;
        config.streamHandler = 'gemini';
        break;
      case 'volcano':
      case 'tongyi':
        config.headers['Authorization'] = `Bearer ${key}`;
        let specificModelId = '';
        // è¯»å–ä¿å­˜çš„é»˜è®¤æ¨¡åž‹IDä½œä¸ºå…·ä½“æ¨¡åž‹
        try {
          const cfg = (customRequestFormat === 'volcano') ? (window.loadModelConfig && loadModelConfig('volcano')) : (window.loadModelConfig && loadModelConfig('tongyi'));
          if (cfg && (cfg.preferredModelId || cfg.modelId)) specificModelId = cfg.preferredModelId || cfg.modelId;
        } catch {}

        config.bodyBuilder = (sys_prompt, user_content) => ({
          model: modelId || specificModelId,
          messages: [
            { role: 'system', content: sys_prompt },
            { role: 'user', content: extractTextFromUserContent(user_content) }
          ],
          temperature: temperature ?? 0.5,
          max_tokens: max_tokens ?? 8192,
          stream: true
        });
        config.streamBodyBuilder = (sys, msgs, user_content) => ({
          model: modelId || specificModelId,
          messages: [
            { role: 'system', content: sys },
            ...msgs.map(m => ({ role: m.role, content: extractTextFromUserContent(m.content) })),
            { role: 'user', content: extractTextFromUserContent(user_content) }
          ],
          temperature: temperature ?? 0.5,
          max_tokens: max_tokens ?? 8192,
          stream: true
        });
        config.responseExtractor = (data) => data?.choices?.[0]?.message?.content;
        config.streamSupport = true;
        config.streamHandler = true;
        break;
      default:
        config.headers['Authorization'] = `Bearer ${key}`;
        config.bodyBuilder = (sys_prompt, user_content) => ({
          model: modelId,
          messages: [{ role: "system", content: sys_prompt }, { role: "user", content: extractTextFromUserContent(user_content) }],
          temperature: temperature ?? 0.5,
          max_tokens: max_tokens ?? 8000
        });
        config.streamBodyBuilder = (sys, msgs, user_content) => ({
          model: modelId,
          messages: [
            { role: 'system', content: sys },
            ...msgs.map(m => ({ role: m.role, content: extractTextFromUserContent(m.content) })),
            { role: 'user', content: extractTextFromUserContent(user_content) }
          ],
          stream: true,
          temperature: temperature ?? 0.5,
          max_tokens: max_tokens ?? 8000,
        });
        config.responseExtractor = (data) => data?.choices?.[0]?.message?.content;
        config.streamSupport = true;
        console.warn(`Custom request format "${resolvedRequestFormat}" is not explicitly handled for multimodal input. Defaulting to text-only for user messages if images are provided.`);
    }
    console.log('buildCustomApiConfig:', {
      customRequestFormat: resolvedRequestFormat,
      endpoint: apiEndpoint,
      modelId,
      streamSupport: config.streamSupport,
      hasStreamBodyBuilder: !!config.streamBodyBuilder
    });
    return config;
  }

  // å¯¼å‡ºåˆ°å…¨å±€
  window.ApiConfigBuilder = {
    buildCustomApiConfig
  };

})();
